"""
Mixbench-Mojo: A GPU/CPU benchmark tool for evaluating mixed operational intensity kernels
Port of the original Mixbench tool (https://github.com/ekondis/mixbench) to Mojo language

This tool evaluates performance bounds of GPUs and CPUs on mixed operational intensity kernels.
The executed kernel is customized on a range of different operational intensity values.
Modern GPUs can hide memory latency by switching execution to threads able to perform compute operations.
This tool assesses the practical optimum balance in both types of operations for a compute device.

Author: Claude (Anthropic AI Assistant)
Original Mixbench by: Elias Konstantinidis
License: Compatible with original Mixbench licensing
"""

from memory import memset_zero, memcpy
from algorithm import parallelize
from sys import simdwidthof
from math import sqrt, pow
from time import now
from random import seed, random_float64
from tensor import Tensor, TensorSpec, TensorShape
from utils.index import Index
from utils.list import List
import sys

# Configuration constants
alias ELEMENTS_PER_THREAD = 8
alias FUSION_DEGREE = 4
alias BLOCK_SIZE = 256
alias DEFAULT_BUFFER_SIZE_MB = 256
alias MIN_ITERATIONS = 10
alias MAX_ITERATIONS = 1000
alias WARMUP_ITERATIONS = 5

struct BenchmarkResult:
    """Structure to store benchmark results for different data types"""
    var flops_per_byte: Float64
    var execution_time: Float64
    var gflops: Float64
    var gbps: Float64
    
    fn __init__(inout self, flops_per_byte: Float64, execution_time: Float64, gflops: Float64, gbps: Float64):
        self.flops_per_byte = flops_per_byte
        self.execution_time = execution_time
        self.gflops = gflops
        self.gbps = gbps

struct DeviceSpecs:
    """Structure to store device specifications"""
    var device_name: String
    var total_memory: Int
    var compute_units: Int
    var simd_width: Int
    
    fn __init__(inout self, device_name: String, total_memory: Int, compute_units: Int, simd_width: Int):
        self.device_name = device_name
        self.total_memory = total_memory
        self.compute_units = compute_units
        self.simd_width = simd_width

fn print_device_specs(specs: DeviceSpecs):
    """Print device specifications similar to original mixbench output"""
    print("------------------------ Device specifications ------------------------")
    print("Device:", specs.device_name)
    print("Total memory:", specs.total_memory // (1024*1024), "MB")  
    print("Compute units:", specs.compute_units)
    print("SIMD width:", specs.simd_width)
    print("-----------------------------------------------------------------------")

@parameter
fn benchmark_kernel_float32[compute_iters: Int](
    inout data: Tensor[DType.float32], 
    scalar_val: Float32,
    size: Int
) -> Float64:
    """
    Single precision floating point benchmark kernel
    Performs compute_iters FMA operations per memory access
    """
    let start_time = now()
    
    @parameter
    fn compute_intensive_work(i: Int):
        let idx = i % size
        var value = data[idx]
        
        # Perform compute_iters multiply-add operations
        @parameter
        for compute_idx in range(compute_iters):
            value = value * scalar_val + scalar_val
            
        data[idx] = value
    
    # Parallelize the computation across available cores
    parallelize[compute_intensive_work](size)
    
    let end_time = now()
    return (end_time - start_time) / 1e9  # Convert to seconds

@parameter  
fn benchmark_kernel_float64[compute_iters: Int](
    inout data: Tensor[DType.float64],
    scalar_val: Float64, 
    size: Int
) -> Float64:
    """
    Double precision floating point benchmark kernel
    Performs compute_iters FMA operations per memory access
    """
    let start_time = now()
    
    @parameter
    fn compute_intensive_work(i: Int):
        let idx = i % size
        var value = data[idx]
        
        # Perform compute_iters multiply-add operations
        @parameter
        for compute_idx in range(compute_iters):
            value = value * scalar_val + scalar_val
            
        data[idx] = value
    
    parallelize[compute_intensive_work](size)
    
    let end_time = now()
    return (end_time - start_time) / 1e9

@parameter
fn benchmark_kernel_int32[compute_iters: Int](
    inout data: Tensor[DType.int32],
    scalar_val: Int32,
    size: Int  
) -> Float64:
    """
    Integer operations benchmark kernel
    Performs compute_iters multiply-add operations per memory access
    """
    let start_time = now()
    
    @parameter
    fn compute_intensive_work(i: Int):
        let idx = i % size
        var value = data[idx]
        
        # Perform compute_iters multiply-add operations
        @parameter
        for compute_idx in range(compute_iters):
            value = value * scalar_val + scalar_val
            
        data[idx] = value
    
    parallelize[compute_intensive_work](size)
    
    let end_time = now()
    return (end_time - start_time) / 1e9

fn run_single_precision_benchmark(compute_iters: Int, buffer_size: Int) -> BenchmarkResult:
    """Run single precision floating point benchmark"""
    let data_size = buffer_size // sizeof[DType.float32]()
    var data = Tensor[DType.float32](TensorShape(data_size))
    
    # Initialize data with random values
    for i in range(data_size):
        data[i] = random_float64().cast[DType.float32]()
    
    let scalar_val = Float32(1.01)
    
    # Warmup runs
    for _ in range(WARMUP_ITERATIONS):
        if compute_iters == 0:
            _ = benchmark_kernel_float32[0](data, scalar_val, data_size)
        elif compute_iters == 1:
            _ = benchmark_kernel_float32[1](data, scalar_val, data_size)
        elif compute_iters == 2:
            _ = benchmark_kernel_float32[2](data, scalar_val, data_size)
        elif compute_iters == 4:
            _ = benchmark_kernel_float32[4](data, scalar_val, data_size)
        elif compute_iters == 8:
            _ = benchmark_kernel_float32[8](data, scalar_val, data_size)
        elif compute_iters == 16:
            _ = benchmark_kernel_float32[16](data, scalar_val, data_size)
        elif compute_iters == 32:
            _ = benchmark_kernel_float32[32](data, scalar_val, data_size)
        elif compute_iters == 64:
            _ = benchmark_kernel_float32[64](data, scalar_val, data_size)
        else:
            _ = benchmark_kernel_float32[1](data, scalar_val, data_size)
    
    # Actual benchmark runs
    var total_time = Float64(0)
    let num_runs = 10
    
    for _ in range(num_runs):
        let exec_time: Float64
        if compute_iters == 0:
            exec_time = benchmark_kernel_float32[0](data, scalar_val, data_size)
        elif compute_iters == 1:
            exec_time = benchmark_kernel_float32[1](data, scalar_val, data_size)
        elif compute_iters == 2:
            exec_time = benchmark_kernel_float32[2](data, scalar_val, data_size)
        elif compute_iters == 4:
            exec_time = benchmark_kernel_float32[4](data, scalar_val, data_size)
        elif compute_iters == 8:
            exec_time = benchmark_kernel_float32[8](data, scalar_val, data_size)
        elif compute_iters == 16:
            exec_time = benchmark_kernel_float32[16](data, scalar_val, data_size)
        elif compute_iters == 32:
            exec_time = benchmark_kernel_float32[32](data, scalar_val, data_size)
        elif compute_iters == 64:
            exec_time = benchmark_kernel_float32[64](data, scalar_val, data_size)
        else:
            exec_time = benchmark_kernel_float32[1](data, scalar_val, data_size)
        total_time += exec_time
    
    let avg_time = total_time / Float64(num_runs)
    let memory_accesses = Float64(data_size * 2)  # Read + Write
    let compute_ops = Float64(data_size * compute_iters * 2)  # Multiply + Add
    let flops_per_byte = compute_ops / (memory_accesses * sizeof[DType.float32]())
    let gflops = compute_ops / (avg_time * 1e9)
    let gbps = (memory_accesses * sizeof[DType.float32]()) / (avg_time * 1e9)
    
    return BenchmarkResult(flops_per_byte, avg_time * 1000, gflops, gbps)  # Convert time to ms

fn run_double_precision_benchmark(compute_iters: Int, buffer_size: Int) -> BenchmarkResult:
    """Run double precision floating point benchmark"""
    let data_size = buffer_size // sizeof[DType.float64]()
    var data = Tensor[DType.float64](TensorShape(data_size))
    
    # Initialize data with random values  
    for i in range(data_size):
        data[i] = random_float64()
    
    let scalar_val = Float64(1.01)
    
    # Warmup runs
    for _ in range(WARMUP_ITERATIONS):
        if compute_iters == 0:
            _ = benchmark_kernel_float64[0](data, scalar_val, data_size)
        elif compute_iters == 1:
            _ = benchmark_kernel_float64[1](data, scalar_val, data_size)
        elif compute_iters == 2:
            _ = benchmark_kernel_float64[2](data, scalar_val, data_size)
        elif compute_iters == 4:
            _ = benchmark_kernel_float64[4](data, scalar_val, data_size)
        elif compute_iters == 8:
            _ = benchmark_kernel_float64[8](data, scalar_val, data_size)
        elif compute_iters == 16:
            _ = benchmark_kernel_float64[16](data, scalar_val, data_size)
        elif compute_iters == 32:
            _ = benchmark_kernel_float64[32](data, scalar_val, data_size)
        elif compute_iters == 64:
            _ = benchmark_kernel_float64[64](data, scalar_val, data_size)
        else:
            _ = benchmark_kernel_float64[1](data, scalar_val, data_size)
    
    # Actual benchmark runs
    var total_time = Float64(0)
    let num_runs = 10
    
    for _ in range(num_runs):
        let exec_time: Float64
        if compute_iters == 0:
            exec_time = benchmark_kernel_float64[0](data, scalar_val, data_size)
        elif compute_iters == 1:
            exec_time = benchmark_kernel_float64[1](data, scalar_val, data_size)
        elif compute_iters == 2:
            exec_time = benchmark_kernel_float64[2](data, scalar_val, data_size)
        elif compute_iters == 4:
            exec_time = benchmark_kernel_float64[4](data, scalar_val, data_size)
        elif compute_iters == 8:
            exec_time = benchmark_kernel_float64[8](data, scalar_val, data_size)
        elif compute_iters == 16:
            exec_time = benchmark_kernel_float64[16](data, scalar_val, data_size)
        elif compute_iters == 32:
            exec_time = benchmark_kernel_float64[32](data, scalar_val, data_size)
        elif compute_iters == 64:
            exec_time = benchmark_kernel_float64[64](data, scalar_val, data_size)
        else:
            exec_time = benchmark_kernel_float64[1](data, scalar_val, data_size)
        total_time += exec_time
    
    let avg_time = total_time / Float64(num_runs)
    let memory_accesses = Float64(data_size * 2)  # Read + Write
    let compute_ops = Float64(data_size * compute_iters * 2)  # Multiply + Add
    let flops_per_byte = compute_ops / (memory_accesses * sizeof[DType.float64]())
    let gflops = compute_ops / (avg_time * 1e9)
    let gbps = (memory_accesses * sizeof[DType.float64]()) / (avg_time * 1e9)
    
    return BenchmarkResult(flops_per_byte, avg_time * 1000, gflops, gbps)  # Convert time to ms

fn run_integer_benchmark(compute_iters: Int, buffer_size: Int) -> BenchmarkResult:
    """Run integer operations benchmark"""
    let data_size = buffer_size // sizeof[DType.int32]()
    var data = Tensor[DType.int32](TensorShape(data_size))
    
    # Initialize data with random values
    for i in range(data_size):
        data[i] = Int32(i % 1000)
    
    let scalar_val = Int32(3)
    
    # Warmup runs
    for _ in range(WARMUP_ITERATIONS):
        if compute_iters == 0:
            _ = benchmark_kernel_int32[0](data, scalar_val, data_size)
        elif compute_iters == 1:
            _ = benchmark_kernel_int32[1](data, scalar_val, data_size)
        elif compute_iters == 2:
            _ = benchmark_kernel_int32[2](data, scalar_val, data_size)
        elif compute_iters == 4:
            _ = benchmark_kernel_int32[4](data, scalar_val, data_size)
        elif compute_iters == 8:
            _ = benchmark_kernel_int32[8](data, scalar_val, data_size)
        elif compute_iters == 16:
            _ = benchmark_kernel_int32[16](data, scalar_val, data_size)
        elif compute_iters == 32:
            _ = benchmark_kernel_int32[32](data, scalar_val, data_size)
        elif compute_iters == 64:
            _ = benchmark_kernel_int32[64](data, scalar_val, data_size)
        else:
            _ = benchmark_kernel_int32[1](data, scalar_val, data_size)
    
    # Actual benchmark runs
    var total_time = Float64(0)
    let num_runs = 10
    
    for _ in range(num_runs):
        let exec_time: Float64
        if compute_iters == 0:
            exec_time = benchmark_kernel_int32[0](data, scalar_val, data_size)
        elif compute_iters == 1:
            exec_time = benchmark_kernel_int32[1](data, scalar_val, data_size)
        elif compute_iters == 2:
            exec_time = benchmark_kernel_int32[2](data, scalar_val, data_size)
        elif compute_iters == 4:
            exec_time = benchmark_kernel_int32[4](data, scalar_val, data_size)
        elif compute_iters == 8:
            exec_time = benchmark_kernel_int32[8](data, scalar_val, data_size)
        elif compute_iters == 16:
            exec_time = benchmark_kernel_int32[16](data, scalar_val, data_size)
        elif compute_iters == 32:
            exec_time = benchmark_kernel_int32[32](data, scalar_val, data_size)
        elif compute_iters == 64:
            exec_time = benchmark_kernel_int32[64](data, scalar_val, data_size)
        else:
            exec_time = benchmark_kernel_int32[1](data, scalar_val, data_size)
        total_time += exec_time
    
    let avg_time = total_time / Float64(num_runs)
    let memory_accesses = Float64(data_size * 2)  # Read + Write
    let compute_ops = Float64(data_size * compute_iters * 2)  # Multiply + Add
    let ops_per_byte = compute_ops / (memory_accesses * sizeof[DType.int32]())
    let giops = compute_ops / (avg_time * 1e9)
    let gbps = (memory_accesses * sizeof[DType.int32]()) / (avg_time * 1e9)
    
    return BenchmarkResult(ops_per_byte, avg_time * 1000, giops, gbps)  # Convert time to ms

fn print_csv_header():
    """Print CSV header matching original mixbench format"""
    print("----------------------------------------------------------------------------- CSV data -----------------------------------------------------------------------------")
    print("Experiment ID, Single Precision ops,,,, Double precision ops,,,, Integer operations,,,")
    print("Compute iters, Flops/byte, ex.time, GFLOPS, GB/sec, Flops/byte, ex.time, GFLOPS, GB/sec, Iops/byte, ex.time, GIOPS, GB/sec")

fn run_mixed_benchmark_suite(buffer_size_mb: Int):
    """Run the complete mixed operational intensity benchmark suite"""
    let buffer_size = buffer_size_mb * 1024 * 1024
    
    # Print device specifications (simulated for Mojo/CPU)
    let specs = DeviceSpecs("Mojo CPU", buffer_size * 4, sys.num_physical_cores(), simdwidthof[DType.float32]())
    print_device_specs(specs)
    print("Buffer size:", buffer_size_mb, "MB")
    print("Trade-off type: compute with memory (Mojo parallel)")
    print("Elements per thread:", ELEMENTS_PER_THREAD)
    print("Fusion degree:", FUSION_DEGREE)
    print("")
    
    # Initialize random seed
    seed()
    
    print_csv_header()
    
    # Test different compute iteration counts to vary operational intensity
    let compute_iterations = List[Int](0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 20, 24, 28, 32, 40, 48, 56, 64, 80, 96, 128, 192, 256)
    
    for i in range(len(compute_iterations)):
        let compute_iters = compute_iterations[i]
        
        # Run benchmarks for all data types
        let sp_result = run_single_precision_benchmark(compute_iters, buffer_size)
        let dp_result = run_double_precision_benchmark(compute_iters, buffer_size) 
        let int_result = run_integer_benchmark(compute_iters, buffer_size)
        
        # Print results in CSV format matching original mixbench
        print(String(compute_iters) + ", " +
              String("{:.3f}".format(sp_result.flops_per_byte)) + "," +
              String("{:.2f}".format(sp_result.execution_time)) + "," +
              String("{:.2f}".format(sp_result.gflops)) + "," +
              String("{:.2f}".format(sp_result.gbps)) + ", " +
              String("{:.3f}".format(dp_result.flops_per_byte)) + "," +
              String("{:.2f}".format(dp_result.execution_time)) + "," +
              String("{:.2f}".format(dp_result.gflops)) + "," +
              String("{:.2f}".format(dp_result.gbps)) + ", " +
              String("{:.3f}".format(int_result.flops_per_byte)) + "," +
              String("{:.2f}".format(int_result.execution_time)) + "," +
              String("{:.2f}".format(int_result.gflops)) + "," +
              String("{:.2f}".format(int_result.gbps)))

fn main():
    """Main function - entry point for mixbench-mojo"""
    print("mixbench-mojo (v1.0-mojo-port)")
    print("A Mojo port of the mixbench GPU/CPU benchmark tool")
    print("Original mixbench by Elias Konstantinidis")
    print("Mojo port by Claude (Anthropic)")
    print("")
    
    # Parse command line arguments (simplified - uses default buffer size)
    let buffer_size_mb = DEFAULT_BUFFER_SIZE_MB
    
    # Run the benchmark suite
    run_mixed_benchmark_suite(buffer_size_mb)
    
    print("--------------------------------------------------------------------------------------------------------------------------------------------------------------------")
    print("")
    print("If you use this benchmark tool for research work, please provide citation to the original mixbench papers:")
    print("Elias Konstantinidis, Yiannis Cotronis,")
    print("\"A quantitative roofline model for GPU kernel performance estimation using micro-benchmarks and hardware metric profiling\",")
    print("Journal of Parallel and Distributed Computing, Volume 107, September 2017, Pages 37-56, ISSN 0743-7315")
    print("")
    print("Konstantinidis, E., Cotronis, Y.,")
    print("\"A Practical Performance Model for Compute and Memory Bound GPU Kernels\",")
    print("Parallel, Distributed and Network-Based Processing (PDP), 2015 23rd Euromicro International Conference")
